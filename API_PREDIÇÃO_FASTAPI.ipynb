{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYrSH4rE7Q4FqjvLsAuq/x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matheusalvesmartins/API_predictDealsClosings_RealTime_CRM/blob/main/API_PREDI%C3%87%C3%83O_FASTAPI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xY3vsDM40ycW"
      },
      "outputs": [],
      "source": [
        "!pip install fastapi uvicorn scikit-learn pandas joblib requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bibliotecas para manipulaÃ§Ã£o de dataset\n",
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "# Bibliotecas para manipulaÃ§Ã£o de arquivos\n",
        "from google.colab import files\n",
        "\n",
        "# Bibliotecas para operaÃ§Ãµes estatÃ­sticas e matemÃ¡ticas\n",
        "import numpy as np\n",
        "\n",
        "# Bibliotecas para interaÃ§Ãµes com API\n",
        "import requests\n",
        "import time\n",
        "\n",
        "# Bibliotecas de aprendizado de mÃ¡quina\n",
        "from sklearn.model_selection import train_test_split, learning_curve\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder, TargetEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Bibliotecas para visualizaÃ§Ã£o de dados\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "ghXyCdsT2Q4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi uvicorn transformers"
      ],
      "metadata": {
        "id": "LxIM_0UY3PPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yaI1WdO03WTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "IYC2Wi7W3-ek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2zeYUTOZlyoGXtl3hIPYBaC45n7_7R17CPD4oGkFPUvbY8yt8"
      ],
      "metadata": {
        "id": "d7oBBSPZ49XO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar dependÃªncias no Colab (executar uma vez)\n",
        "!pip install fastapi nest-asyncio pyngrok uvicorn scikit-learn transformers\n",
        "\n",
        "# Imports\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import requests\n",
        "import ast\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from transformers import pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\n",
        "# Habilita o FastAPI no Jupyter/Colab\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Carrega o modelo salvo\n",
        "modelo_pipeline = joblib.load(\"modelo_predicao_fechamento_ploomes.pkl\")\n",
        "\n",
        "# Define colunas esperadas (exemplo: vocÃª pode ajustar)\n",
        "numerical = ['ValorNegocio']\n",
        "categorical = ['EstagioAtual', 'StatusAtual', 'MOC', 'OrigemMarketing', 'ERP', 'CRM',\n",
        "               'OrigemLead', 'Campanha', 'RangeFinanceiro', 'SentimentoCenario', 'Indicacao']\n",
        "\n",
        "# Pipeline de sentimento\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "\n",
        "# FunÃ§Ãµes auxiliares\n",
        "def analisar_sentimento(texto):\n",
        "    if pd.isnull(texto) or not isinstance(texto, str) or texto.strip() == \"\":\n",
        "        return pd.Series([None, None])\n",
        "    resultado = sentiment_pipeline(texto[:512])[0]\n",
        "    return pd.Series([resultado['label'], resultado['score']])\n",
        "\n",
        "def consultar_dados_brutos_dealid(deal_id, user_key, base_url):\n",
        "    url = base_url.replace(\"$ID\", str(deal_id))\n",
        "    headers = {\"User-Key\": user_key}\n",
        "    response = requests.get(url, headers=headers)\n",
        "    if response.status_code != 200:\n",
        "        return None\n",
        "    registros = response.json().get(\"value\", [])\n",
        "    return pd.DataFrame(registros) if registros else None\n",
        "\n",
        "def preprocessar_dados_dealid(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
        "    df_raw = df_raw.copy()\n",
        "\n",
        "    for campo in [\"Stage\", \"Status\"]:\n",
        "        if campo in df_raw.columns:\n",
        "            df_raw[campo] = df_raw[campo].apply(\n",
        "                lambda x: ast.literal_eval(x)[\"Name\"] if isinstance(x, str) and x.startswith(\"{\") else (x.get(\"Name\") if isinstance(x, dict) else None)\n",
        "            )\n",
        "\n",
        "    if \"Contact\" in df_raw.columns:\n",
        "        df_raw[\"Contact\"] = df_raw['Contact'].apply(\n",
        "            lambda x: x['OtherProperties'][0]['ObjectValueName'] if isinstance(x, dict) and x.get('OtherProperties') else None\n",
        "        )\n",
        "\n",
        "    df_main = df_raw.rename(columns={\n",
        "        \"Id\": \"DealId\",\n",
        "        \"ContactId\": \"Cliente\",\n",
        "        \"CreateDate\": \"DataCriacao\",\n",
        "        \"Amount\": \"ValorNegocio\",\n",
        "        \"Stage\": \"EstagioAtual\",\n",
        "        \"Status\": \"StatusAtual\",\n",
        "        \"Contact\": \"MOC\"\n",
        "    })\n",
        "\n",
        "    df_main = df_main[[\"DealId\", \"Cliente\", \"DataCriacao\", \"ValorNegocio\", \"EstagioAtual\", \"StatusAtual\", \"MOC\"]]\n",
        "\n",
        "    df_merge = df_main.copy()\n",
        "    if \"OtherProperties\" in df_raw.columns:\n",
        "        def tentar_avaliar(val):\n",
        "            if isinstance(val, str) and val.startswith(\"[\"):\n",
        "                try: return ast.literal_eval(val)\n",
        "                except: return None\n",
        "            return val\n",
        "\n",
        "        df_raw[\"OtherProperties\"] = df_raw[\"OtherProperties\"].apply(tentar_avaliar)\n",
        "\n",
        "        lista_dealids, lista_props = [], []\n",
        "        for _, row in df_raw.iterrows():\n",
        "            props = row[\"OtherProperties\"]\n",
        "            if isinstance(props, list):\n",
        "                for prop in props:\n",
        "                    lista_dealids.append(row[\"Id\"])\n",
        "                    lista_props.append(prop)\n",
        "\n",
        "        df_other_exploded = pd.DataFrame(lista_props)\n",
        "        df_other_exploded[\"DealId\"] = lista_dealids\n",
        "        df_other_exploded[\"valor_utilizado\"] = (\n",
        "            df_other_exploded.get(\"ObjectValueName\")\n",
        "            .fillna(df_other_exploded.get(\"StringValue\"))\n",
        "            .fillna(df_other_exploded.get(\"BigStringValue\"))\n",
        "        )\n",
        "\n",
        "        df_other_pivot = df_other_exploded.pivot_table(\n",
        "            index=\"DealId\", columns=\"FieldKey\", values=\"valor_utilizado\", aggfunc=\"first\"\n",
        "        ).reset_index()\n",
        "\n",
        "        df_other_pivot.columns.name = None\n",
        "        df_other_pivot = df_other_pivot.rename(columns={\n",
        "            'deal_40906D65-7DCE-4AB1-8D65-F8C142526A41': 'OrigemMarketing',\n",
        "            'deal_467BB847-34B8-4052-AD55-FB279305CDB7': 'DepartamentoContato',\n",
        "            'deal_4DAD0A30-82C0-4A91-AC60-9C40B4D8BA31': 'ERP',\n",
        "            'deal_52AA059C-64B8-45E3-8CCC-127229FCAB38': 'CRM',\n",
        "            'deal_537A27B9-0DC0-4D12-A975-84E9919598D4': 'OrigemLead',\n",
        "            'deal_174F0306-11FC-41EA-B575-8794E71CD3CF': 'CenÃ¡rio',\n",
        "            'deal_CFBD676E-69E3-408A-9E07-944322B26116': 'Campanha',\n",
        "            'deal_8B3220DB-2F09-4219-BF7A-65CF2381B9F1': 'ClienteIndicador'\n",
        "        })\n",
        "\n",
        "        df_merge = pd.merge(df_merge, df_other_pivot, on=\"DealId\", how=\"left\")\n",
        "\n",
        "    df_merge[\"Indicacao\"] = df_merge.get(\"ClienteIndicador\").notnull()\n",
        "    df_merge[\"RangeFinanceiro\"] = pd.cut(df_merge[\"ValorNegocio\"], bins=[0, 2000, 5000, 10000, 20000, float('inf')],\n",
        "                                         labels=['2k', '5k', '10k', '20k', '20k+'])\n",
        "\n",
        "    if \"CenÃ¡rio\" in df_merge.columns:\n",
        "        df_merge[[\"SentimentoCenario\", \"ScoreSentimento\"]] = df_merge[\"CenÃ¡rio\"].apply(analisar_sentimento)\n",
        "\n",
        "    col_remover = ['ClienteIndicador', 'DepartamentoContato', 'TamanhoEmpresa', 'Estrutura',\n",
        "                   'Cliente', 'DataCriacao', 'EstagioAtual', 'CenÃ¡rio', 'CoreBusiness', 'ScoreSentimento']\n",
        "    df_merge = df_merge.drop(columns=[c for c in col_remover if c in df_merge.columns])\n",
        "\n",
        "    for col in numerical + categorical:\n",
        "        if col not in df_merge.columns:\n",
        "            df_merge[col] = None\n",
        "\n",
        "    return df_merge[numerical + categorical]\n",
        "\n",
        "# --- CriaÃ§Ã£o da API\n",
        "app = FastAPI(title=\"API de PrediÃ§Ã£o - Oportunidades Ploomes\")\n",
        "\n",
        "class InputData(BaseModel):\n",
        "    deal_id: int\n",
        "    user_key: str\n",
        "    base_url: str\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "def predict(data: InputData):\n",
        "    df_raw = consultar_dados_brutos_dealid(data.deal_id, data.user_key, data.base_url)\n",
        "    if df_raw is None:\n",
        "        return {\"erro\": \"Dados nÃ£o encontrados para esse DealID.\"}\n",
        "\n",
        "    df_tratado = preprocessar_dados_dealid(df_raw)\n",
        "    proba = modelo_pipeline.predict_proba(df_tratado)[0]\n",
        "    idx_positiva = list(modelo_pipeline.classes_).index(\"Ganha\")\n",
        "    prob_ganha = proba[idx_positiva]\n",
        "    pred = \"Ganha\" if prob_ganha >= 0.35 else \"Perdida\"\n",
        "\n",
        "    return {\n",
        "        \"deal_id\": data.deal_id,\n",
        "        \"classe_predita\": pred,\n",
        "        \"probabilidades\": {\"Perdida\": float(proba[1-idx_positiva]), \"Ganha\": float(prob_ganha)}\n",
        "    }\n",
        "\n",
        "# --- Executando a API via tÃºnel ngrok\n",
        "public_url = ngrok.connect(8000)\n",
        "print(f\"ðŸ”— Swagger disponÃ­vel em: {public_url}/docs\")\n",
        "\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
      ],
      "metadata": {
        "id": "Kdr1Uh8g3_DI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SQdZWMOp4AQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import requests\n",
        "from transformers import pipeline\n",
        "import ast\n",
        "\n",
        "# --- Carregar modelo treinado\n",
        "modelo_pipeline = joblib.load(\"modelo_predicao_fechamento_ploomes.pkl\")\n",
        "\n",
        "# --- Base URL fixa (conforme fornecido)\n",
        "BASE_URL = \"https://api2-s04-app.ploomes.com/Deals?$filter=Id eq $ID+and+true+and+PipelineId+eq+33669&$select=Id,Title,Editable,FirstTaskDate,ContactId,LastQuoteId,LastOrderId,LastDocumentId,StageId,StatusId,PipelineId,Stage,Status,Pipeline,Title,CreateDate,Amount&$expand=Stage($select=Id,Ordination,PipelineId,LastPipelineStage),Status,Owner($select=Id,Name),Creator($select=Id,Name),Pipeline($select=Id,ForbiddenStageReturn,MustPassAllStages,Stages;$expand=Stages),Contact($select=Id,Name,Editable,OwnerId,TypeId),Stage($select=Id,Name,PipelineId,Pipeline,Ordination,LastPipelineStage),Status($select=Id,Name),OtherProperties($expand=CurrencyValue;$filter=FieldId+eq+39587+or+FieldId+eq+68681+or+FieldId+eq+43491+or+FieldId+eq+128142+or+FieldId+eq+89075+or+FieldId+eq+30029262+or+FieldId+eq+56606+or+FieldId+eq+30029253+or+FieldId+eq+27199+or+FieldId+eq+61673+or+FieldId+eq+44134+or+FieldId+eq+30803),Contact($select=Id,OtherProperties;$expand=OtherProperties($filter=FieldId+eq+30008919))&$orderby=CreateDate+desc,Id&preload=true\"\n",
        "\n",
        "# --- Pipeline de sentimento (se necessÃ¡rio)\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "\n",
        "# --- Dados de entrada da API\n",
        "class EntradaAPI(BaseModel):\n",
        "    deal_id: int\n",
        "    user_key: str\n",
        "\n",
        "# --- FunÃ§Ã£o de consulta Ã  API do Ploomes\n",
        "def consultar_dados_brutos_dealid(deal_id, user_key):\n",
        "    url = BASE_URL.replace(\"$ID\", str(deal_id))\n",
        "    headers = {\"User-Key\": user_key}\n",
        "    response = requests.get(url, headers=headers)\n",
        "    if response.status_code != 200:\n",
        "        return None\n",
        "    dados = response.json().get(\"value\", [])\n",
        "    if not dados:\n",
        "        return None\n",
        "    return pd.DataFrame(dados)\n",
        "\n",
        "# --- PrÃ©-processamento (resumo adaptado do seu)\n",
        "def preprocessar_dados_dealid(df_raw):\n",
        "    df_raw = df_raw.copy()\n",
        "\n",
        "    for campo in [\"Stage\", \"Status\"]:\n",
        "        if campo in df_raw.columns:\n",
        "            df_raw[campo] = df_raw[campo].apply(\n",
        "                lambda x: ast.literal_eval(x)[\"Name\"] if isinstance(x, str) and x.startswith(\"{\") else (\n",
        "                    x.get(\"Name\") if isinstance(x, dict) else None\n",
        "                )\n",
        "            )\n",
        "\n",
        "    if \"Contact\" in df_raw.columns:\n",
        "        df_raw[\"Contact\"] = df_raw['Contact'].apply(\n",
        "            lambda x: x['OtherProperties'][0]['ObjectValueName'] if isinstance(x, dict) and x.get('OtherProperties') else None\n",
        "        )\n",
        "\n",
        "    df_main = df_raw.rename(columns={\n",
        "        \"Id\": \"DealId\",\n",
        "        \"ContactId\": \"Cliente\",\n",
        "        \"CreateDate\": \"DataCriacao\",\n",
        "        \"Amount\": \"ValorNegocio\",\n",
        "        \"Stage\": \"EstagioAtual\",\n",
        "        \"Status\": \"StatusAtual\",\n",
        "        \"Contact\": \"MOC\"\n",
        "    })\n",
        "\n",
        "    df_main = df_main[[\"DealId\", \"Cliente\", \"DataCriacao\", \"ValorNegocio\", \"EstagioAtual\", \"StatusAtual\", \"MOC\"]]\n",
        "\n",
        "    df_merge = df_main.copy()\n",
        "\n",
        "    if \"OtherProperties\" in df_raw.columns:\n",
        "        def tentar_avaliar(val):\n",
        "            if isinstance(val, str) and val.startswith(\"[\"):\n",
        "                try:\n",
        "                    return ast.literal_eval(val)\n",
        "                except Exception:\n",
        "                    return None\n",
        "            return val\n",
        "\n",
        "        df_raw[\"OtherProperties\"] = df_raw[\"OtherProperties\"].apply(tentar_avaliar)\n",
        "\n",
        "        lista_dealids = []\n",
        "        lista_props = []\n",
        "\n",
        "        for _, row in df_raw.iterrows():\n",
        "            deal_id = row[\"Id\"]\n",
        "            props = row[\"OtherProperties\"]\n",
        "            if isinstance(props, list):\n",
        "                for prop in props:\n",
        "                    lista_dealids.append(deal_id)\n",
        "                    lista_props.append(prop)\n",
        "\n",
        "        df_other_exploded = pd.DataFrame(lista_props)\n",
        "        df_other_exploded[\"DealId\"] = lista_dealids\n",
        "\n",
        "        df_other_exploded[\"valor_utilizado\"] = (\n",
        "            df_other_exploded.get(\"ObjectValueName\")\n",
        "            .fillna(df_other_exploded.get(\"StringValue\"))\n",
        "            .fillna(df_other_exploded.get(\"BigStringValue\"))\n",
        "        )\n",
        "\n",
        "        df_other_pivot = df_other_exploded.pivot_table(\n",
        "            index=\"DealId\",\n",
        "            columns=\"FieldKey\",\n",
        "            values=\"valor_utilizado\",\n",
        "            aggfunc=\"first\"\n",
        "        ).reset_index()\n",
        "\n",
        "        df_merge = pd.merge(df_merge, df_other_pivot, on=\"DealId\", how=\"left\")\n",
        "\n",
        "    df_merge[\"Indicacao\"] = df_merge.get(\"ClienteIndicador\").notnull()\n",
        "    df_merge[\"RangeFinanceiro\"] = pd.cut(\n",
        "        df_merge[\"ValorNegocio\"],\n",
        "        bins=[0, 2000, 5000, 10000, 20000, float('inf')],\n",
        "        labels=['2k', '5k', '10k', '20k', '20k+']\n",
        "    )\n",
        "\n",
        "    if \"CenÃ¡rio\" in df_merge.columns:\n",
        "        df_merge[[\"SentimentoCenario\", \"ScoreSentimento\"]] = df_merge[\"CenÃ¡rio\"].apply(analisar_sentimento)\n",
        "\n",
        "    col_remover = [\n",
        "        'ClienteIndicador', 'DepartamentoContato', 'TamanhoEmpresa',\n",
        "        'Estrutura', 'Cliente', 'DataCriacao',\n",
        "        'EstagioAtual', 'CenÃ¡rio', 'CoreBusiness', 'ScoreSentimento'\n",
        "    ]\n",
        "    df_merge = df_merge.drop(columns=[c for c in col_remover if c in df_merge.columns], errors=\"ignore\")\n",
        "\n",
        "    colunas_esperadas = modelo_pipeline.feature_names_in_\n",
        "    for col in colunas_esperadas:\n",
        "        if col not in df_merge.columns:\n",
        "            df_merge[col] = None\n",
        "    df_merge = df_merge[colunas_esperadas]\n",
        "\n",
        "    return df_merge\n",
        "\n",
        "# --- InstÃ¢ncia da API FastAPI\n",
        "app = FastAPI()\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "def predict_entrada(dados: EntradaAPI):\n",
        "    df_raw = consultar_dados_brutos_dealid(dados.deal_id, dados.user_key)\n",
        "\n",
        "    if df_raw is None:\n",
        "        return {\"erro\": \"NÃ£o foi possÃ­vel obter os dados para o DealId informado.\"}\n",
        "\n",
        "    df_tratado = preprocessar_dados_dealid(df_raw)\n",
        "\n",
        "    probas = modelo_pipeline.predict_proba(df_tratado)[0]\n",
        "    pos_idx = list(modelo_pipeline.classes_).index(\"Ganha\")\n",
        "    threshold = 0.35\n",
        "    classe = \"Ganha\" if probas[pos_idx] >= threshold else \"Perdida\"\n",
        "\n",
        "    return {\n",
        "        \"DealId\": dados.deal_id,\n",
        "        \"Classe\": classe,\n",
        "        \"Probabilidades\": {\n",
        "            \"Perdida\": round(probas[1 - pos_idx], 3),\n",
        "            \"Ganha\": round(probas[pos_idx], 3)\n",
        "        }\n",
        "    }\n"
      ],
      "metadata": {
        "id": "PDMpzosg7wmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi pyngrok uvicorn nest_asyncio"
      ],
      "metadata": {
        "id": "KtfYSevh7yUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "\n",
        "nest_asyncio.apply()\n",
        "public_url = ngrok.connect(8000)\n",
        "print(f\"ðŸ”— Acesse a interface da API via Swagger: {public_url}/docs\")\n",
        "\n",
        "uvicorn.run(app, port=8000)\n"
      ],
      "metadata": {
        "id": "-WqfT6GX75BG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mhZ6vRPA7-Ov"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}